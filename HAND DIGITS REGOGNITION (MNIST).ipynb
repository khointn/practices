{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST HAND-DIGITS REGCONITION\n",
    "\n",
    "## Introduction & Dataset\n",
    "\n",
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large and famous database of handwritten digits that is commonly used for training various image processing systems. Since MNIST is like the \"Hello World\" of machine learning with, I have tried out a few machine learning algorithms to enhanced my skills and get acquainted to the algorithms.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "This is my assignment for Developer Innovation Challenge of Facebook & Coder School VN\n",
    "\n",
    "## Objective\n",
    "\n",
    "I used 2 method to train this data: \n",
    "**Decision Tree & Random Forest\n",
    "Neural Network**\n",
    "\n",
    "Mainly used libraries: Sklearn, GridSearchCV to build model and train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easy to understand how this data set was built, I get an example image, which contains number 7 from mist.\n",
    "1. Resize it from 28x28 to 10X10 and make diagram. Each pixel in image contains value from 0 to 255. The greater the number, the whiter the color. That is the way how people encode the image. [Link](https://www.scan2cad.com/tips/bitmap-vs-vector/) for further information.\n",
    "2. Because each observation should be one line in dataset so we reshape 2-D array to 1-D array. Using 1-D array as feature vector and label it. In our case, it's 7.\n",
    "3. Do it again with the other images from mist. We will have a table with feature vector and label. Take a close look at first and third observation. The pattern of them are much similar than second observation. Base on this thing, we hope that can build a model that classify a number using feature vector.\n",
    "\n",
    "Let's do it.\n",
    "\n",
    "**Illustration Picture (copy from internet)**\n",
    "![Imgur](https://i.imgur.com/wtFCKS3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Asus\\Downloads\\Dataset\\CSML_W4\\data\\train.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 7, 3, 5, 8, 9, 2, 6], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all unique values are there in 'label', expect to see a list from 0 to 9\n",
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines X and y for train_test_split \n",
    "# y is the column 'label' and X is rest (784 pixel columns)\n",
    "list1=[]\n",
    "for i in range(784):\n",
    "    list1.append(str('pixel'+str(i)))\n",
    "X=np.array(data[list1])\n",
    "y=np.array([data['label']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "# Split X and y to X_train, y_train, X_test, y_test with 20% test size and random state 101\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertd some example of our data back to image\n",
    "# Print out y_train[index] which is the number of the image\n",
    "# Using plt.imshow(img, cmap='gray') to plot the image 28x28 in height and width.\n",
    "# Before plotting, transformed the vector X_train[index] into 28x28 Matrix with the function reshape()\n",
    "#Try the number with index is 36\n",
    "index = 36\n",
    "print(\"Label: \" + str(y_train[index]))\n",
    "plt.imshow(X_train[index].reshape((28,28)),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD 1: DECISION TREE & RANDOM FOREST USING SKLEARN TOOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest & Decision Tree\n",
    "# Defined two classifier called rfc and dtc represent RandomForestClassifier and DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_predict=dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Fit training data to Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier as rc\n",
    "rfc=rc()\n",
    "rfc.fit(X_train,y_train)\n",
    "y_predictrfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398809523809524"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the models to testing set and take a look at accuracy score.\n",
    "# Random Forest model:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_predictrfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8513095238095238"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree model:\n",
    "accuracy_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x226800beba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualized the heatmap for confusion matrix of Random Forest model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_predictrfc)\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x226801dc4a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap for confusion matrix of Decision Tree model as well:\n",
    "cm=confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "[Further reading](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Base on the accuracy score I decided to take Random Forest as Classifier and improved it\n",
    "# Defined an array of number called 'n'- the set of 'n_estimators' (number of \"Tree\") that was going apply to our Random Forest algorithms\n",
    "n = [1 ,5 ,10, 20, 50, 100, 200, 500]\n",
    "result = []\n",
    "# Using a for-loop which goes through n\n",
    "# Inside the loop defined a new RandomForestClassifier model with appropriate 'n_estimators'\n",
    "# Applied the model on X_test and calculate the accuracy score then save it into 'result'\n",
    "for i in n:\n",
    "    clf = RandomForestClassifier(i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    result.append(accuracy_score(y_test,predictions))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8078571428571428, 0.9019047619047619, 0.9402380952380952, 0.9554761904761905, 0.9632142857142857, 0.9673809523809523, 0.9663095238095238, 0.9688095238095238]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(result,n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pickle to export the trained model\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rfc, open(os.path.join(r'C:\\Users\\Asus\\Downloads\\Dataset', 'HandDigitsPrediction.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Asus\\Downloads\\Dataset\\HandDigitsPrediction.pkl', 'rb') as function:\n",
    " function=pickle.load(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed up training process using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:714: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=6,\n",
       "             param_grid={'n_estimators': [1, 5, 10, 20, 50, 100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid={\n",
    "    'n_estimators':[1,5,10,20,50,100,200,500]\n",
    "}\n",
    "\n",
    "gridcv=GridSearchCV(RandomForestClassifier(),params_grid,n_jobs= 6)\n",
    "gridcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616666666666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.804172</td>\n",
       "      <td>0.136739</td>\n",
       "      <td>0.123338</td>\n",
       "      <td>0.056002</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>0.780684</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.775029</td>\n",
       "      <td>0.772738</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.903899</td>\n",
       "      <td>0.025892</td>\n",
       "      <td>0.119348</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "      <td>0.904758</td>\n",
       "      <td>0.892143</td>\n",
       "      <td>0.886755</td>\n",
       "      <td>0.894554</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.036876</td>\n",
       "      <td>0.097264</td>\n",
       "      <td>0.192155</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.935999</td>\n",
       "      <td>0.928036</td>\n",
       "      <td>0.924265</td>\n",
       "      <td>0.929435</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.394568</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>0.236701</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>0.944851</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.673441</td>\n",
       "      <td>0.426452</td>\n",
       "      <td>0.527589</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.962064</td>\n",
       "      <td>0.955714</td>\n",
       "      <td>0.951237</td>\n",
       "      <td>0.956339</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.340240</td>\n",
       "      <td>0.400269</td>\n",
       "      <td>0.906579</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.965009</td>\n",
       "      <td>0.958839</td>\n",
       "      <td>0.956060</td>\n",
       "      <td>0.959970</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64.361225</td>\n",
       "      <td>0.200251</td>\n",
       "      <td>1.626651</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>200</td>\n",
       "      <td>{'n_estimators': 200}</td>\n",
       "      <td>0.965277</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>0.955970</td>\n",
       "      <td>0.960804</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115.367694</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>3.265234</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>0.965813</td>\n",
       "      <td>0.960982</td>\n",
       "      <td>0.958203</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.804172      0.136739         0.123338        0.056002   \n",
       "1       4.903899      0.025892         0.119348        0.003291   \n",
       "2       4.036876      0.097264         0.192155        0.003291   \n",
       "3       7.394568      0.040367         0.236701        0.022878   \n",
       "4      15.673441      0.426452         0.527589        0.031790   \n",
       "5      30.340240      0.400269         0.906579        0.017333   \n",
       "6      64.361225      0.200251         1.626651        0.070372   \n",
       "7     115.367694      0.454314         3.265234        0.047712   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                  1    {'n_estimators': 1}           0.780684   \n",
       "1                  5    {'n_estimators': 5}           0.904758   \n",
       "2                 10   {'n_estimators': 10}           0.935999   \n",
       "3                 20   {'n_estimators': 20}           0.950549   \n",
       "4                 50   {'n_estimators': 50}           0.962064   \n",
       "5                100  {'n_estimators': 100}           0.965009   \n",
       "6                200  {'n_estimators': 200}           0.965277   \n",
       "7                500  {'n_estimators': 500}           0.965813   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.762500           0.775029         0.772738        0.007599   \n",
       "1           0.892143           0.886755         0.894554        0.007544   \n",
       "2           0.928036           0.924265         0.929435        0.004891   \n",
       "3           0.943750           0.940252         0.944851        0.004275   \n",
       "4           0.955714           0.951237         0.956339        0.004442   \n",
       "5           0.958839           0.956060         0.959970        0.003740   \n",
       "6           0.961161           0.955970         0.960804        0.003808   \n",
       "7           0.960982           0.958203         0.961667        0.003144   \n",
       "\n",
       "   rank_test_score  \n",
       "0                8  \n",
       "1                7  \n",
       "2                6  \n",
       "3                5  \n",
       "4                4  \n",
       "5                3  \n",
       "6                2  \n",
       "7                1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe using gridcv\n",
    "pd.DataFrame(gridcv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD 2: Logistic Regression\n",
    "Instead of building code lines with gradient descent algorithm (as I did with the Titanic Dataset), I will use Sklearn this time. But I also add the function which represented the Logistic Regression as a additional lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDITIONAL LINE\n",
    "#sigmoid function:\n",
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDITIONAL LINE\n",
    "#gradient descent:\n",
    "def logistic_regression(x,y,w_init,eta,tol=1e-5,max_count=100000000000):\n",
    "    m=x.shape[0]\n",
    "    n=x.shape[1]\n",
    "    w=[w_init]\n",
    "    count=0\n",
    "    check=20\n",
    "    while count<max_count:\n",
    "        mix=np.random.permutation(m)\n",
    "        for i in mix:\n",
    "            xi=x[i,:].reshape(n,1)\n",
    "            yi=y[i]\n",
    "            zi=sigmoid(np.dot(w[-1].T,xi))\n",
    "            w_new=w[-1]+eta*(yi-zi)*xi\n",
    "            count+=1\n",
    "            #stop\n",
    "            if count%check==0:\n",
    "                if np.linalg.norm(w_new-w[-check])<tol:\n",
    "                    return w[-1]\n",
    "            w.append(w_new)\n",
    "    return w[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "m=X_train.shape[0]\n",
    "n=X_train.shape[1]\n",
    "WW={}\n",
    "for i in range(10):# for each of digits from 0 to 10, we train it seperately.One loop will represent for 1 digit training.\n",
    "    list1=[]\n",
    "    for k in range(y_train.shape[0]): #resize the train data into 1 and 0 (1 is positive when y is the number training, else if y not the number training, y=0)\n",
    "        if y_train[k]==i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "    y1=np.array(list1)\n",
    "    clf = LogisticRegression().fit(X_train, y1)\n",
    "    y_predict=clf.predict_proba(X_train)\n",
    "    WW[i]=y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=[]\n",
    "for i in range(10):\n",
    "    list2.append(WW[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the lens of train result\n",
    "len(list2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_new={}\n",
    "for i in range(10):\n",
    "    listt=[]\n",
    "    for k in range(len(list2[i])):\n",
    "        listt.append(list2[i][k][1])\n",
    "        list_new[i]=listt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proba=pd.DataFrame(list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proba.to_csv('data_proba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975045e-44</td>\n",
       "      <td>3.847470e-87</td>\n",
       "      <td>6.012537e-23</td>\n",
       "      <td>1.129601e-11</td>\n",
       "      <td>4.336411e-25</td>\n",
       "      <td>1.924193e-40</td>\n",
       "      <td>1.832616e-60</td>\n",
       "      <td>9.635738e-01</td>\n",
       "      <td>3.057692e-12</td>\n",
       "      <td>5.620166e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.190756e-08</td>\n",
       "      <td>3.067718e-24</td>\n",
       "      <td>2.616751e-02</td>\n",
       "      <td>8.194145e-02</td>\n",
       "      <td>1.572645e-04</td>\n",
       "      <td>1.698436e-03</td>\n",
       "      <td>1.498423e-23</td>\n",
       "      <td>8.664674e-01</td>\n",
       "      <td>7.963643e-03</td>\n",
       "      <td>6.896132e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.490513e-04</td>\n",
       "      <td>8.458936e-03</td>\n",
       "      <td>4.005551e-03</td>\n",
       "      <td>3.593487e-01</td>\n",
       "      <td>1.485200e-03</td>\n",
       "      <td>4.953043e-02</td>\n",
       "      <td>8.034572e-29</td>\n",
       "      <td>8.807708e-03</td>\n",
       "      <td>3.703759e-02</td>\n",
       "      <td>9.975709e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.999103e-01</td>\n",
       "      <td>6.606115e-83</td>\n",
       "      <td>7.643282e-04</td>\n",
       "      <td>1.443970e-04</td>\n",
       "      <td>4.057213e-07</td>\n",
       "      <td>4.078687e-04</td>\n",
       "      <td>8.104660e-06</td>\n",
       "      <td>1.588764e-04</td>\n",
       "      <td>2.183415e-04</td>\n",
       "      <td>1.708118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.366401e-06</td>\n",
       "      <td>9.999779e-01</td>\n",
       "      <td>8.057694e-02</td>\n",
       "      <td>1.883796e-02</td>\n",
       "      <td>1.120224e-04</td>\n",
       "      <td>5.998305e-05</td>\n",
       "      <td>2.879090e-14</td>\n",
       "      <td>2.737263e-03</td>\n",
       "      <td>1.301027e-01</td>\n",
       "      <td>6.372595e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.893065e-03</td>\n",
       "      <td>1.912588e-43</td>\n",
       "      <td>7.060639e-05</td>\n",
       "      <td>8.144045e-03</td>\n",
       "      <td>1.504738e-06</td>\n",
       "      <td>9.435324e-01</td>\n",
       "      <td>4.559206e-09</td>\n",
       "      <td>3.503884e-09</td>\n",
       "      <td>2.749533e-02</td>\n",
       "      <td>1.575646e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.057199e-11</td>\n",
       "      <td>3.974918e-17</td>\n",
       "      <td>2.685620e-05</td>\n",
       "      <td>5.699865e-01</td>\n",
       "      <td>1.419288e-06</td>\n",
       "      <td>8.835505e-03</td>\n",
       "      <td>1.672772e-35</td>\n",
       "      <td>7.966016e-04</td>\n",
       "      <td>6.712216e-03</td>\n",
       "      <td>8.891904e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.997552e-01</td>\n",
       "      <td>1.867777e-53</td>\n",
       "      <td>1.976484e-05</td>\n",
       "      <td>5.617452e-05</td>\n",
       "      <td>1.211852e-06</td>\n",
       "      <td>2.455819e-04</td>\n",
       "      <td>2.269798e-05</td>\n",
       "      <td>1.655246e-21</td>\n",
       "      <td>8.211308e-03</td>\n",
       "      <td>1.584365e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.125977e-05</td>\n",
       "      <td>1.354190e-21</td>\n",
       "      <td>1.261640e-04</td>\n",
       "      <td>9.936329e-01</td>\n",
       "      <td>6.106287e-11</td>\n",
       "      <td>8.929819e-03</td>\n",
       "      <td>3.356834e-07</td>\n",
       "      <td>2.734506e-05</td>\n",
       "      <td>4.570474e-04</td>\n",
       "      <td>4.555001e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.595372e-10</td>\n",
       "      <td>9.999847e-01</td>\n",
       "      <td>2.844329e-02</td>\n",
       "      <td>9.799486e-03</td>\n",
       "      <td>2.939586e-06</td>\n",
       "      <td>1.153297e-03</td>\n",
       "      <td>9.476692e-04</td>\n",
       "      <td>5.175800e-15</td>\n",
       "      <td>2.413872e-02</td>\n",
       "      <td>4.589744e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  7.975045e-44  3.847470e-87  6.012537e-23  1.129601e-11  4.336411e-25   \n",
       "1  1.190756e-08  3.067718e-24  2.616751e-02  8.194145e-02  1.572645e-04   \n",
       "2  3.490513e-04  8.458936e-03  4.005551e-03  3.593487e-01  1.485200e-03   \n",
       "3  9.999103e-01  6.606115e-83  7.643282e-04  1.443970e-04  4.057213e-07   \n",
       "4  2.366401e-06  9.999779e-01  8.057694e-02  1.883796e-02  1.120224e-04   \n",
       "5  3.893065e-03  1.912588e-43  7.060639e-05  8.144045e-03  1.504738e-06   \n",
       "6  5.057199e-11  3.974918e-17  2.685620e-05  5.699865e-01  1.419288e-06   \n",
       "7  9.997552e-01  1.867777e-53  1.976484e-05  5.617452e-05  1.211852e-06   \n",
       "8  3.125977e-05  1.354190e-21  1.261640e-04  9.936329e-01  6.106287e-11   \n",
       "9  3.595372e-10  9.999847e-01  2.844329e-02  9.799486e-03  2.939586e-06   \n",
       "\n",
       "              5             6             7             8             9  \n",
       "0  1.924193e-40  1.832616e-60  9.635738e-01  3.057692e-12  5.620166e-11  \n",
       "1  1.698436e-03  1.498423e-23  8.664674e-01  7.963643e-03  6.896132e-02  \n",
       "2  4.953043e-02  8.034572e-29  8.807708e-03  3.703759e-02  9.975709e-03  \n",
       "3  4.078687e-04  8.104660e-06  1.588764e-04  2.183415e-04  1.708118e-04  \n",
       "4  5.998305e-05  2.879090e-14  2.737263e-03  1.301027e-01  6.372595e-03  \n",
       "5  9.435324e-01  4.559206e-09  3.503884e-09  2.749533e-02  1.575646e-01  \n",
       "6  8.835505e-03  1.672772e-35  7.966016e-04  6.712216e-03  8.891904e-02  \n",
       "7  2.455819e-04  2.269798e-05  1.655246e-21  8.211308e-03  1.584365e-04  \n",
       "8  8.929819e-03  3.356834e-07  2.734506e-05  4.570474e-04  4.555001e-10  \n",
       "9  1.153297e-03  9.476692e-04  5.175800e-15  2.413872e-02  4.589744e-04  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot \n",
    "data_proba.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_proba=np.array(data_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_upred=[]\n",
    "for i in array_proba:\n",
    "    count=-1\n",
    "    for k in i:\n",
    "        count+=1\n",
    "        if max(i)==k:\n",
    "            y_upred.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the accuracy\n",
    "accuracy_score(y_train,y_upred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "Since Random Forest enable its user to upgrade the accuracy by using a \"Forest of Decision Tree\", its accuracy was much higher than the ordinary Decision Tree method (0.939 vs 0.851)\n",
    "\n",
    "In the hyperparameter tunning, I tested a group of hyperparameters, which were represent number of \"Tree\" in a Random Forest. As you can see in the plotted map, we can see the more larger number the more accurate it was (but took more time to train). It seemed that 100 trees are enough to create an acceptable accuracy\n",
    "\n",
    "The Logistic Regression trained and has acceptable accuracy. But it was time-consuming when I trained it, more than the 500-tree I used in Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
